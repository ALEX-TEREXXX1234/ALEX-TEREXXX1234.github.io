<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<title>Лабораторная работа №12</title>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1251">
<script language="JavaScript" type="text/JavaScript">
<!--
function MM_preloadImages() { //v3.0
  var d=document; if(d.images){ if(!d.MM_p) d.MM_p=new Array();
    var i,j=d.MM_p.length,a=MM_preloadImages.arguments; for(i=0; i<a.length; i++)
    if (a[i].indexOf("#")!=0){ d.MM_p[j]=new Image; d.MM_p[j++].src=a[i];}}
}

function MM_findObj(n, d) { //v4.01
  var p,i,x;  if(!d) d=document; if((p=n.indexOf("?"))>0&&parent.frames.length) {
    d=parent.frames[n.substring(p+1)].document; n=n.substring(0,p);}
  if(!(x=d[n])&&d.all) x=d.all[n]; for (i=0;!x&&i<d.forms.length;i++) x=d.forms[i][n];
  for(i=0;!x&&d.layers&&i<d.layers.length;i++) x=MM_findObj(n,d.layers[i].document);
  if(!x && d.getElementById) x=d.getElementById(n); return x;
}

function MM_nbGroup(event, grpName) { //v6.0
  var i,img,nbArr,args=MM_nbGroup.arguments;
  if (event == "init" && args.length > 2) {
    if ((img = MM_findObj(args[2])) != null && !img.MM_init) {
      img.MM_init = true; img.MM_up = args[3]; img.MM_dn = img.src;
      if ((nbArr = document[grpName]) == null) nbArr = document[grpName] = new Array();
      nbArr[nbArr.length] = img;
      for (i=4; i < args.length-1; i+=2) if ((img = MM_findObj(args[i])) != null) {
        if (!img.MM_up) img.MM_up = img.src;
        img.src = img.MM_dn = args[i+1];
        nbArr[nbArr.length] = img;
    } }
  } else if (event == "over") {
    document.MM_nbOver = nbArr = new Array();
    for (i=1; i < args.length-1; i+=3) if ((img = MM_findObj(args[i])) != null) {
      if (!img.MM_up) img.MM_up = img.src;
      img.src = (img.MM_dn && args[i+2]) ? args[i+2] : ((args[i+1])? args[i+1] : img.MM_up);
      nbArr[nbArr.length] = img;
    }
  } else if (event == "out" ) {
    for (i=0; i < document.MM_nbOver.length; i++) {
      img = document.MM_nbOver[i]; img.src = (img.MM_dn) ? img.MM_dn : img.MM_up; }
  } else if (event == "down") {
    nbArr = document[grpName];
    if (nbArr)
      for (i=0; i < nbArr.length; i++) { img=nbArr[i]; img.src = img.MM_up; img.MM_dn = 0; }
    document[grpName] = nbArr = new Array();
    for (i=2; i < args.length-1; i+=2) if ((img = MM_findObj(args[i])) != null) {
      if (!img.MM_up) img.MM_up = img.src;
      img.src = img.MM_dn = (args[i+1])? args[i+1] : img.MM_up;
      nbArr[nbArr.length] = img;
  } }
}
//-->
</script>
</head>

<body bgcolor="#FFCC99">
<blockquote> 
  <div align="left"> 
    <table border="0" cellpadding="0" cellspacing="0">
      <tr> 
        <td><a href="main12.htm" target="_self" onClick="MM_nbGroup('down','group1','Menu','',1)" onMouseOver="MM_nbGroup('over','Menu','','',1)" onMouseOut="MM_nbGroup('out')"><img src="img/Menu.gif" alt="" name="Menu" width="73" height="22" border="0" onload=""></a></td>
        <td><a href="002.htm" target="_self" onClick="MM_nbGroup('down','group1','For','',1)" onMouseOver="MM_nbGroup('over','For','','',1)" onMouseOut="MM_nbGroup('out')"><img src="img/For.gif" alt="" name="For" width="73" height="22" border="0" onload=""></a></td>
      </tr>
    </table>
  </div>
</blockquote>
<div align="center"> 
  <p align="center"><strong><font size="5"><em>Формирование знаний в системах 
    искусственного интеллекта. </em></font></strong></p>
  <p align="center"><strong><font size="5"><em>Геометрический подход </em></font></strong></p>
  <p align="justify">&nbsp;</p>
  <p align="justify">Развитие компьютеров вступило в этап, когда они начали активно 
    брать на себя различные функции, традиционно считавшиеся прерогативой интеллектуальной 
    деятельности человека. Предпосылок для такой метаморфозы было много. С одной 
    стороны, - это техническое совершенствование вычислительных машин (улучшение 
    технологической базы и архитектуры, повышение производительности и надежности, 
    уменьшение габаритов и стоимости), что сделало их доступными для самого широкого 
    круга людей, не обладающих знаниями профессиональных программистов. С другой 
    стороны, к такому превращению привели разработки в области игровых программ, 
    теории доказательства теорем, распознавания образов, машинного перевода, автоматического 
    реферирования, информационного поиска, сочинения текстов и музыки и т. д.<br>
    В целом можно сказать, что причиной интеллектуализации компьютеров стали исследования, 
    так или иначе моделирующие процесс получения результата в отдельных видах 
    деятельности человека. Вместе с тем главным фактором, определившим становление 
    индустрии интеллектуальных систем и позволившим объединить различные достижения 
    и поднять их на качественно новый уровень, явилось осознание и перенесение 
    главного акцента компьютерных разработок с вычислительных программ на приложения, 
    осуществляющие представление и манипулирование знаниями из актуальных предметных 
    областей. <br>
    В создании интеллектуальных компьютерных систем выделяют следующие основные 
    направления. <br>
    Интеллектуальные информационно-поисковые системы (ИИПС). Они отличаются от 
    предыдущего поколения информационно-поисковых систем не только гораздо более 
    обширным справочно-информационным фондом, но и важнейшей способностью формировать 
    адекватные ответы на запросы пользователя даже тогда, когда запросы не носят 
    прямого характера. Иными словами, ИИПС достаточно «умны» для того, чтобы понять 
    недостаточно четко сформулированные вопросы. Другой особенностью ИИПС является 
    их способность «переваривать» огромные количества информации из разнообразных 
    источников, осуществляя ее автоматическое реферирование и проводя анализ на 
    противоречивость и неполноту тех или иных фрагментов знания. <br>
    Обучающие системы, которые нередко называют «тьюторами» (англ. (to) tutor 
    - обучать), являются разновидностью экспертных систем. Тьюторы, прежде всего, 
    применяются для профессионального обучения будущих специалистов. Здесь на 
    первый план выходят знания о методе. <br>
    Экспертные системы (ЭС) предназначены, главным образом, для решения практических 
    задач, возникающих у специалиста, работающего в слабо структурированной и 
    трудно формализуемой предметной области. Эти системы аккумулируют профессиональные 
    знания опытных квалифицированных экспертов и служат полезным инструментом, 
    содействующим повышению точности и эффективности принимаемых решений.</p>
  <p align="justify">Развитие указанных направлений определяется в настоящее время 
    тремя парадигмами. <br>
    Первая связана с архитектурными решениями на основе параллельных и асинхронно 
    протекающих процессов, перемещающихся по структуре взаимосвязанных однотипных 
    компьютеров. Разработка теории таких процессов - одна из центральных проблем 
    искусственного интеллекта (ИИ). <br>
    Вторая парадигма ИИ - когнитивная компьютерная графика, представляющая собой 
    эффективный технический инструмент воздействия на образное интуитивное мышление 
    исследователя. Функция когнитивной графики заключается в наглядном изображении 
    внутреннего содержания предмета, которым может быть, в частности, любое абстрактное 
    научное понятие, гипотеза или теория. Динамизм компьютерной графики, отсутствие 
    принципиальных ограничений на форму, характер и структуру изображений, за 
    которыми может стоять мощный вычислительный эксперимент, использование дополнительных 
    цветовых и музыкальных эффектов (мультимедиа) открывает «правополушарные» 
    каналы связи между исследователем и интересующей его проблемой. <br>
    Третья парадигма состоит в создании интеллектуальных гибридных систем, обеспечивающих 
    пользователю комфортное взаимодействие с пакетами прикладных программ и делающих 
    доступной для него многогранную область вычислительной математики. <br>
    Актуализация отмеченных парадигм во многом обусловлена экстенсивным увеличением 
    технических возможностей современных компьютеров. В то же время «узким» местом 
    ИИ, в меньшей степени зависящим от наращивания технических мускулов, была 
    и остается проблема получения и манипулирования знаниями, которые составляют 
    основу любой интеллектуальной системы. Эта задача имеет глубинные корни и 
    затрагивает все без исключения аспекты ИИ. <br>
    При решении проблемы получения знаний выделяют три стратегии (Гаврилова Т.А., 
    Червинская К.Р. Извлечение и структурирование знаний в экспертных системах. 
    М.: Радио и связь, 1992): приобретение знаний, извлечение знаний и формирование 
    знаний. <br>
    Под nрио6ретением (acquisition) знаний понимается способ автоматизированного 
    наполнения 6азы знаний посредством диалога эксперта и специальной программы. 
    Автоматизированные средства приобретения знаний получают готовые фрагменты 
    знаний в соответствии со структурами, заложенными разработчиками системы. 
    Большинство соответствующих инструментальных средств ориентировано на конкретные 
    экспертные системы с жестко обозначенной предметной областью и моделью представления 
    знаний. Например, система TEIRESIAS (Davis R. TEIRESIAS: Applications of meta-level 
    knowledge//Knowledge-based Systems in Artifical Intelligence. N.Y.: МсGгоw-Нill, 
    1982) предназначена для пополнения базы знаний системы MYCIN или ее дочерних 
    ветвей, построенных на оболочке EMYCIN (Shortliffe Е. Computer based medical 
    consultations: MYCIN. N.Y.: American Elsevier, 1976) в области медицинской 
    диагностики с использованием продукционной модели представления знаний. При 
    попытке использования систем приобретения знаний в других областях разработчикам 
    нередко приходится сталкиваться со следующими трудностями: <br>
    - неудачный способ прио6ретения, не совпадающий со структурой знаний в данной 
    о6ласти; <br>
    - неадекватная модель представления знаний; <br>
    - отсутствие целостной системы знаний в результате прио6ретения только «фрагментов»; 
    <br>
    - упрощение и уплощение «картины мира» и пр. <br>
    Извлечением (elicitation) знаний называют процедуру взаимодействия инженера 
    по знаниям с источником знаний (экспертом, специальной литературой и др.) 
    6ез использований вычислительной техники. Это длительная и трудоемкая процедура, 
    в которой инженеру по знаниям, владеющему методами когнитивной психологии, 
    системного анализа, математической логики и пр., нужно воссоздать модель предметной 
    06ласти, используемой экспертами для принятия решений. <br>
    Актуальность задачи извлечения знаний при разработке интеллектуальных систем 
    обусловлена следующими причинами. Во-первых, значительная часть знаний эксперта 
    является результатом многочисленных наслоений, ступеней опыта, и эксперт нередко 
    не способен самостоятельно проанализировать все детали в цепи своих умозаключений. 
    Во-вторых, диалог инженера по знаниям и эксперта служит наиболее естественной 
    формой «раскручивания» лабиринтов памяти эксперта, в которых хранятся знания, 
    часто носящие невербальный характер. И в-третьих, многочисленные причинно-следственные 
    связи реальной предметной области образуют сложную систему, скелет которой 
    иногда более доступен для восприятия аналитика, владеющего системной методологией 
    и не обремененного знанием большого количества подробностей. <br>
    Термин «формирование знаний» связывают с созданием компьютерных систем, реализующих 
    методы автоматического получения знания, так называемое «машинное обучение» 
    (machine learning). На сегодняшний день это наиболее перспективное направление 
    инженерии знаний, предполагающее, что в результате автоматизации процесса 
    обучения система «сможет» самостоя-тельно сформировать необходимые знания 
    на основе имеющегося эмпирического материала (данных). В настоящее время специалистам 
    стало ясно, что инженер по знаниям с помощью одного лишь диалога с экспертом 
    в какой-то конкретной области не спосо6ен добыть все нужные для разработки 
    интеллектуальной системы сведения. Требуется еще и множество примеров, на 
    которых удастся обучить машину (Десять лет спустя (интервью с Д.Мичи) // Будущее 
    искусственного интеллекта. М.: Наука, 1991. С. 213-216). <br>
    В самом общем виде: формирование знаний - это задача обработки баз данных 
    (БД) с целью перехода к базам знаний (БЗ). В БД накапливаются и хранятся эмпирические 
    факты из исследуемой предметной области (фактические данные, примеры экспертных 
    заключений, элементарные высказывания с некоторой оценкой и т. п.), представленные 
    в виде троек &lt;о6ъект, признак, значение признака&gt;. В БЗ заносятся сведения, 
    выражающие закономерности структуры множества эмпирических фактов, релевантные 
    прикладному контексту. <br>
    Контекст определяет отношения между объектами из БД. Он может задаваться вне 
    БД (например, экспертом) или продуцироваться признаком (или совокупностью 
    признаков) из БД. Чаще всего на практике встречаются отношения эквивалентности 
    и порядка. Отношения эквивалентности присущи, в частности, задачам классификации, 
    диагностики и распознавания образов. Отношения порядка свойственны задачам 
    шкалирования, прогнозирования и т.п. Ниже пойдет речь в основном об отношениях 
    эквивалентности. <br>
    Методы формирования знаний имеют много общего с решениями упомянутых задач 
    классификации, диагностики и распознавания образов. Но одной из главных отличительных 
    черт первых является функция интерпретации закономерностей, кладущихся в основу 
    правил вхождения объектов в классы эквивалентности. Именно поэтому в инженерии 
    знаний наибольшее распространение получили логические методы, например: «эмпирическое 
    предсказа-ние» (Загоруйко Н.Г. Эмпирическое предсказание. Новосибирск: Наука, 
    1979), «индуктивное формирование понятий» (Гладун В. П. Эвристический поиск 
    в сложных средах. Киев: Наукова думка, 1977; Хант Э., Мартин Дж., Стоун Ф. 
    Моделирование процесса формирования понятий на вычислительной машине. М.: 
    Мир, 1970), «построение квазиаксиоматической теории» (Финн В.К. Интеллектуальные 
    системы: проблемы их развития и социальные последствия// Будущее искусственного 
    интеллекта/ Под ред. К. Е. Левитина и Д. А. Поспелова. М.: Наука, 1991) и 
    др. <br>
    Есть еще одна важная причина, обусловившая приоритет логических методов. Она 
    заключается в сложной системной организации областей, являющихся прерогативой 
    искусственного интеллекта. Они относятся, как правило, к надкибернетическому 
    уровню организации систем (Boulding К.Е. General Systems Theory - The Skeleton 
    of Science // Management Science, 2, 1956), закономерности которого не могут 
    быть достаточно точно описаны на языке ста-тистических или иных аналитических 
    математических моделей (Гик Дж., ван. Прикладная общая теория систем. М.: 
    Мир, 1981). Гибкость и многообразие логических конструкций индуктивного вывода 
    позволяют нередко добиваться успеха при описании сложных систем. Вместе с 
    тем центральной проблемой создания таких конструкций остается проблема перебора 
    большого количества вариантов. При этом отмечается, что совершенно не ясно, 
    как можно распараллелить символьную операцию логического вывода. Отсюда следует, 
    что применение логических методов часто вынуждено опираться на эвристические 
    соображения, не имеющие строгого обоснования. <br>
    Альтернативу логическим символьным методам составляет геометрический подход, 
    переводящий задачу формирования знаний на язык геометрических соотношений 
    между эмпирическими фактами, выступающими целостными информационными единицами 
    и отображаемыми точками в пространстве признаков. Это с одной стороны, делает 
    более понятными критерии и принципы построения правил вхождения объектов в 
    определенные классы эквивалентности, которые основываются на сравнении объектов 
    с помощью мер, имеющих интерпретацию расстояний. С другой стороны, следует 
    иметь в виду, что ис-пользование геометрического подхода при неограниченном 
    расширении множества эмпирических фактов автоматически приводит к минимальным, 
    теоретически достижимым ошибкам при принятии решений. Кроме этого, все операции 
    без затруднений распараллеливаются, а визуализация геометрической структуры 
    множества точек позволяет организовать исследование закономерностей в совокупности 
    эмпирических фактов средствами интерактивной графики. Более того, как будет 
    показано ниже, можно получать, наглядные визуальные представления о логических 
    закономерностях в структуре данных - для этого применяется специальная локальная 
    геометрия. Важность, геометрического подхода к решению задач искусственного 
    интеллекта подчеркивается в кн.: Поспелов Д.А. Искусственный интеллект: фантазии 
    и реальность// Наука и жизнь, 1995, № 6. <br>
    В отличие от символьных логических методов, реализующих операции над признаками, 
    в геометрическом подходе главными элементами выступают объекты, а основным 
    видом операций является определение расстояния между объектами в многомерном 
    пространстве признаков. Геометрический и логический подходы составляют оппозицию, 
    которой соответствует ряд других противопоставлений : конкретное-абстрактное, 
    параллельное-nоследовательное, синтез-анализ, безусловное-условное, экстенсиональное-интенсиональное 
    представление знаний, интуитивное-рациональное, nравоnолушарный- левоnолушарный 
    механизмы мышления и т. п. <br>
    В то же время внутри указанных оппозиций имеется тесная связь. Она выражается 
    в том, что «конкретное одновременно воплощает и абстрактную сущность его, 
    сопричаствует с ним; конкретное - всего лишь знак отвлеченного и всеобщего» 
    (Колесов В. В. Отражение русского менталитета в слове // Человек в зеркале 
    наук. Л.: ЛГУ, 1991. С. 106-124). Так, например, любой конкретный объект есть 
    конъюнкция элементарных событий, представляющих собой попадание значений признаков 
    в определенные интервалы. Или, в частности, классификатор, действующий по 
    принципу минимума расстояния, эквивалентен линейному решающему правилу (Таунсенд 
    К. Фохт Д. Проектирование и программная реализация экспертных систем на персональных 
    ЭВМ. М.: Финансы и статистика, 1990), являющемуся формой интенсионального 
    представления знаний. <br>
    Коренная про6лема геометрического подхода состоит в поиске ответа на вопрос: 
    какие признаки и какую меру следует вы6рать для определения расстояний между 
    объектами В известных методах анализа данных эта задача формулируется, как 
    подбор взвешенной метрики с использованием обучающей и частично обучающей 
    информации (Айвазян С.А., Бежаева 3.И., Старовсров О.В. Классификация многомерных 
    наблюдений. М.: Статистика, 1974) или как оцифровка переменных, основанная 
    на максимизации статистического критерия (Миркин Б.Г. Анализ качественных 
    признаков и структур. М.: Статистика, 1980). Удачное решение указанной задачи 
    геометрически выражается расширением «сферы действия» объектов, выступающих 
    в роли представителей своих классов эквивалентности (Дюк В.А. Компьютерная 
    психодиагностика. СПб: Братство, 1994). Однако способы решения данной задачи 
    в инженерии знаний имеют свои существенные особенности. <br>
    Традиционные методы анализа многомерных данных, опирающиеся на геометрическую 
    метафору, используют представление об общем пространстве признаков для всех 
    объектов и об одинаковой мере, применяемой для оценки их сходства или различия. 
    Такое представление уместно, например, при изучении однородных физических 
    феноменов на статистическом уровне системной организации, в которых объект 
    можно рассматривать как реализацию многомерной случайной величины с ясным 
    физическим смыслом, когда есть все основания интерпретировать зафиксированные 
    особенности объектов как случайные флуктуации, обусловленные воздействием 
    шумов, погрешностями измерительных приборов и т. п. <br>
    В задачах формирования знаний, когда мы имеем дело с системами надкибернетического 
    уровня сложности, каждый объект следует рассматривать как самостоятельный 
    информационный факт (совокупность зафиксированных значений признаков), имеющий 
    важные уникальные особенности. Последние раскрываются путем конструирования 
    для любого объекта собственного пространства признаков и нахождения индивидуальной 
    меры, определяющих иерархию его сходства с другими объектами, релевантную 
    заданному контексту. Без такого раскрытия описания объектов они нивелированы, 
    могут содержать много ненужных, шумящих, отвлекающих и даже вредных деталей, 
    и «сферы действия» объектов как представителей своих классов эквивалентно-сти 
    сужаются (Дюк В. А., 1994). <br>
    Конструирование собственного пространства признаков и нахождение индивидуальной 
    меры будем называть локальным преобразованием пространства признаков. <br>
    Пусть x=(x_ij ), i=(1,N), j=(1,p)- матрица данных, где x_ij - значение j- 
    го признака у i-гo объекта. Тогда задача преобразования описания объекта x_i 
    формулируется как определение контекстно-зависимой локальной взвешенной метрики 
    d_i (x_i,x_j) того или иного типа, обеспечивающей релевантную контексту иерархию 
    близостей (удаленностей) объектов x_j ,j=(1,N) относительно объекта x_j. Например, 
    в случае бинарных признаков это может быть локальная взвешенная метрика Хэмминга 
    <br>
    d_i (x_i,x_j )= w_i^T_ij<br>
    где _ij=(|x_i1-x_j1 |,|x_i2-x_j2 |,…,|x_ip-x_jp |)^T;<br>
    w_i=(_i1,_i2,…,_ip )^T - весовой вектор. <br>
    Как следует из данного выражения, задача определения контекстнозависимой локальной 
    метрики заключается в нахождении линейного преобразования новой векторной 
    переменной _i=|x_i-x|. Для определения такого преобразования подходит хорошо 
    разработанный аппарат методов многомерного линейного анализа данных. Ограничение 
    на применение этих методов накладывается требованием неотрицательности компонент 
    весового вектора _ik (k=(1,p)  ) , так как различие объектов x_i и x_j по 
    какому-либо признаку x_k должно обязательно приводить к увеличению расстояния 
     d_i (x_i,x_j ), либо (в случае _ik=0) вообще не сказываться на изменении 
    расстояния d_i (x_i,x_j ),. В рамках данного раздела ограничимся лишь общими 
    замечаниями о методах построения локальных метрик. <br>
    Критерий качества локальной метрики определяется контекстом, а его конкретная 
    форма задается исследователем. Например, с учетом информации о принадлежности 
    объектов к тем или иным классам эквивалентности это может быть стандартный 
    для линейного дискриминантного анализа критерий, построенный на отношении 
    разброса между классами к внутриклассовому разбросу. Или, имея ввиду ложную 
    неоднородную структуру классов, целесообразнее строить критерий качества на 
    оценке первых к-ближайших к x_i объектов, то есть фактически на локальной 
    оценке отношения правдоподобия в точке x_j (Мешалкин Л.Д. Локальные методы 
    классификации. М.: МГУ, 1969, вып.1. С. 58-59). Также не лишен смысла критерий, 
    основанный на сравнении расстояний от объекта x_i до его q - ближайших соседей 
    из собственного класса с расстояниями до его r - ближайших соседей из других 
    классов и т. п. <br>
    При построении локальной метрики могут использоваться самые различные методы, 
    ориентированные на максимизацию заданного критерия. Нередко достаточно ограничиться 
    только отбором центрированных признаков |x_ik- x_jk |. Это бывает целесообразно, 
    главным образом, при работе с бинарными признаками. Для решения данной задачи 
    особенно эффективны алгоритмы отбора переменных типа «плюс минус r» (Кittler 
    J.А. Feature set search algorithms// Ргос. Cjnf. оn Pattern Recogn. And Signal 
    Processing. Paris, France, 25 June-4 July, 1978. Рр. 41-60) и эволюционные 
    методы. В частности, как показывает опыт, хорошо себя зарекомендовал метод 
    случайного поиска с адаптацией (Лбов Г. С. Выбор эффективной системы зависимых 
    признаков // Труды Сиб. отд. АН СССР: Вычислительные системы. Новосибирск, 
    1965, вып. 19. С. 87-101). <br>
    Индивидуально сконструированные локальные метрики обеспечивают каждому объекту, 
    как представителю своего класса, максимально возможную «сферу действия», чего 
    нельзя достигнуть при построении общего пространства признаков и использовании 
    одинаковой метрики для всех объектов. Описание каждого эмпирического факта 
    оказывается полностью избавленным от неинформативных элементов, что позволяет 
    в дальнейшем иметь дело с чистыми «незашумленными» структурами данных. В этом 
    описании остается только то, что действительно важно для отражения сходства 
    и различия между эмпирическими фактами в контексте решаемой задачи. <br>
    В свете представлений о контекстно-зависимых локальных метриках очевидно, 
    что один и тот же объект может поворачиваться разными гранями своего многомерного 
    описания сообразно заданному контексту. К любому объекту, запечатленному в 
    памяти как целостная многомерная структура, «привязан» набор различных локальных 
    метрик, каждая из которых оптимизирует иерархию его сходства (различия) с 
    другими объектами соответственно целям определенной задачи отражения отношений 
    между объектами реального или идеального мира. <br>
    Представление о контекстно-зависимых локальных метриках позволяет объяснить 
    случаи нарушения метрических отношений между элементами матрицы данных, которые 
    наблюдаются в отдельных экспериментах по изучению феноменов психического отражения 
    с помощью техники парных сравнений. Например, в кн.: Крылов В. Ю. «Метод многомерной 
    геометризации психоло-гических данных. Системный подход в математической психологии 
    // Принцип системности в психологических исследованиях». М.:Наука, 1990. С. 
    33-48, описан эксперимент, где респондент, сравнивая «активную деятельную 
    жизнь» (x_1), «жизненную мудрость» (x_2) и «здоровье» (x_3), дал следующие 
    оценки парных различий этих объектов: d_12=2,d_13=1,d_23=7 . Содержательно 
    это означает, что респондент считает близкими ценности «активная деятельная 
    жизнь» и «жизненная мудрость», а также «активная деятельная жизнь» и «здоровье». 
    Однако считает далекими «здоровье» и «жизненную мудрость». Тем самым, хотя 
    данные оценки (каждая по отдельности) являются интуитивно приемлемыми, их 
    нельзя интерпретировать как геометрические расстояния между ценностями (нарушено 
    неравенство треугольника: d_23&lt;d_12+d_13и, соответственно, невозможно изобразить 
    исследуемые объекты в виде точек в некотором статическом субъективном семантическом 
    пространстве ценностных ориентаций. <br>
    Отмеченный факт объясняется существованием у испытуемого не одного, а нескольких 
    субъективных подпространств с различными свойствами (локальными метриками). 
    Так как внешние условия эксперимента являются постоянными, то смена локальных 
    метрик может происходить вследствие изменения контекста, инициируемого различными 
    парами сравниваемых объектов. Это влечет за собой разнокачественное восприятие 
    сходства объектов и выражается в нарушении метрической аксиомы неравенства 
    треугольника, которого бы не произошло, если бы субъективное пространство 
    оставалось неизменным в ходе всего эксперимента. <br>
    В задачах отражения отношений эквивалентности (например, проблемах диагностики 
    или распознавания образов) после построения локальной метрики каждый объект 
    может интерпретироваться как самостоятельный линейный классификатор с некоторыми 
    оптимальными свойствами, определяемыми применявшимся критерием. Соответственно 
    вся выборка данных должна рассматриваться с учетом совокупности N локально 
    оптимальных линейных классификаторов. Для исследования их взаимодействия с 
    целью формулирования конечных выводов пригодны известные подходы к построению 
    решающих правил, достаточно подробно изложенные в литературе (Растригин Л.А., 
    Эренштейн Р.Х. Метод коллективного распознавания. М.: Энергоиздат, 1981. С. 
    1-78; Вешторт А. М., 3уев Ю. А., Краснопрошин В.В. Двухуровневая схема распознавания 
    с логическим корректором// Распознавание, классификация, прогноз. Математические 
    методы и их применение. М.: Наука, 1989. Вып. 2. С. 73-98). В то же время 
    про ведение такого исследования возможно в русле все той же геометрической 
    метафоры. <br>
    В результате построения локальных метрик  d_i (x_i,x_j )=d_ij^((L)) отношения 
    между объектами выражаются матрицей удаленностей D^((L))=( d_i_k^((L) 
    ) ),i,k=(1,N) . Так как локальные метрики у разных объектов могут не совпадать, 
    то для элементов матрицы D^((L)) могут не выполняться требования симметричности 
    и неравенства треугольника. Поэтому данная матрица, хотя и отражает отношения 
    различия между объектами, не может истолковываться как матрица расстояний. 
    <br>
    Для устранения нарушений метрических отношений между элементами <br>
    матрицы D^((L)) вводится специальный класс d^((s)) - метрик. Он определяется 
    следующим образом: d^((s)) (x_i,x_j )=a•S[(d_ik^((L) ) ),(d_jk^((L) ))]+b,k=(1,N) 
    <br>
    где d_ik^((L) ) и d_jk^((L) ) - элементы I -й и j-й строк матрицы D^((L)); 
    (d_ik^((L) ) )- монотонное преобразование d_ik^((L) ), либо преобразование 
    в классификационный показатель (d_ik^((L) ) )=_m (k), где m=rank(d_ik^((L) 
    ) ) и (k)=K_k - номер класса, к которому принадлежит ; S[.,..]- мера подобия 
    или различия двух последовательностей (d_ik^((L) ) ) и (d_jk^((L) ) ); a 
    и b - константы, значения которых подбираются с целью масштабирования и выполнения 
    метрической аксиомы неравенства треугольника (так называемая модель с аддитивной 
    константой (Саrrо J. D., Chang J. J. Analysis of Individual Differences in 
    Multidimensional Scaling via аn Generalization of Ecart-Young Decomposition// 
    Psychometrica, 1970, v. 35, N5. Рр. 283-319; Справочник по прикладной статистике. 
    В 2-х т. Т.2/ Под ред. Э.Ллойда, У.Ледермана, С.А. Айвазяна, Ю.Н. Тюрина. 
    М.: Финансы и статистика, 1990). <br>
    Расстояние между объектами x_i и x_j, измеренное в d^((s)) -метрике, имеет 
    ясный смысл. Образно говоря, если окинуть взором множество объектов из точки, 
    занимаемой объектом x_i, в пространстве специально сконструированном для x_i, 
    то для наблюдателя объекты выстроятся в ряд по степени удаленности от данной 
    точки. С другой точки x_j и в другом пространстве ряд удаленностей тех же 
    самых объектов будет иметь свой специфический вид. Мера сходства (различия) 
    этих рядов S, подвергнутая линейному преобразованию с целью выполнения метрической 
    аксиоматики, есть d^((s)) - расстояние между объектами x_i и x_j.<br>
    Класс d^((s))- метрик отличается большим разнообразием, которое определяется 
    множеством употребляемых преобразований  и мер подобия S. <br>
    Выбор конкретного преобразования  зависит от того, на каком аспекте структуры 
    данных исследователь решает сделать акцент. Например, для получения ранговой 
    величины (d_ik^((L) ) )=rank(d_ik^((L) ) ) может использоваться преобразование 
    d_ik^((L) ). Это следует делать тогда, когда интерес представляет порядок 
    удаленностей изучаемых объектов от x_i. Другой вариант - преобразование d_ik^((L) 
    ) в классификационный показатель. В этом случае все объекты, про ранжированные 
    по удаленности от x_i, заменяются идентификатором своего класса, образно говоря, 
    «окрашиваются» в цвета своего класса. <br>
    Выбор меры S зависит, с одной стороны, от вида преобразования  и, с другой 
    стороны, от того, какие особенности рядов (d_ik^((L) ) ) и (d_jk^((L) ) 
    ), k=(1,N)  имеется намерение оттенить при определении их сходства (различия). 
    Прямой способ основан на вычислении расстояния (например, евклидова) между 
    (d_ik^((L) ) ) и (d_jk^((L) ) ). В данном случае не требуется дальнейшего 
    подбора констант а и b для соблюдения метрических требований, так как они 
    выполняются автоматически. Однако бывает более целесообразно использовать 
    в качестве меры S тот или иной коэффициент связи, например, коэффициент корреляции 
    Пирсона,  Кендалла и др. Если преобразование (d_ik^((L) ) ) дает классификационную 
    переменную, то мерой подобия может служить какой-либо коэффициент сопряженности 
    для номинальных переменных. <br>
    В качестве примера приведем вариант d^((s))- метрики, <br>
    где (d_ik^((L) ) )=rank(d_ik^((L) ) ) , а мерой подобия служит  Кендалла: 
    <br>
    d^((x) ) (x_i,x_j )=(1-_ij)/2<br>
    где _ij=[(d_ik^((L) ) ),(d_jk^((L) ) )]k=(1,N) .<br>
    Значения d^((x) ) (x_i,x_j ) изменяются в пределах от 0 до 1 и для данной 
    меры различия объектов x_i и x_j всегда выполняются метрические требования 
    симметричности и неравенства треугольника (Дюк В.А., 1994). <br>
    После перехода от матрицы D^((L)) к матрице d^((s))- расстояний исследование 
    совокупности объектов с привязанными к ним собственными локальными метриками 
    может производиться всеми доступными методами и алгоритмами, использующими 
    геометрическую метафору данных. Сюда относятся алгоритмы автоматического группирования 
    (кластерный анализ, иерархическое группирование, определение «точек сгущения») 
    (Айвазян С.А., Бухштабер В.М., Енюков И.С., Мешалкин Л. Д. Прикладная статистика. 
    Классификация и снижение размерности. М.: Финансы и статистика, 1989) и методы 
    визуализации данных, для которых исходной информацией служит матрица расстояний 
    (Дэйвисон М. Многомерное шкалирование: Методы наглядного представления данных. 
    М.: Финансы и статистика, 1987), адаптивная развертка (Дюк В. А., 1994). <br>
    Анализ геометрической структуры данных является творческой задачей, не имеющей 
    готовых шаблонов. Например, полезную информацию о стратификационной структуре 
    матрицы d^((s))-расстояний удается извлечь с помощью алгоритмов иерархического 
    группирования данных. Осмысление выделенных группировок на различных шагах 
    работы того или иного дивизимного или агломеративного алгоритма дает возможность 
    получить ответы на вопросы, что общего (различного) имеется между группировками 
    объектов. Это, в свою очередь, способствует построению системы понятий, определению 
    метапонятий и установлению между ними семантических отношений, то есть проведению 
    концептуального анализа знаний. Использование методов проецирования данных 
    на плоскость или в 3-мерные объемы латентных переменных, полученных методами 
    многомерного шкалирования, позволяет разглядеть закономерности в структуре 
    множества эмпирических фактов с оптимизированными описаниями. С одной стороны, 
    увиденные закономерности могут составить основу для минимизации базы знаний, 
    представленных в экстенсиональной форме (например, для определения композиции 
    диагностических прецедентов минимального объема). С другой стороны, выявленные 
    закономерности способствуют разработке тех или иных интенсиональных правил 
    вывода на знаниях. <br>
    Имеется еще одна ценная возможность использования визуальных отображений полученных 
    геометрических структур данных. Ее предоставляют средства современной интерактивной 
    графики, которые позволяют обосновывать принятие решения о принадлежности 
    неизвестного объекта какому-либо классу эквивалентности, получая ответы на 
    вопросы типа: «Что общего у данного объекта с другим объектом или группой 
    объектов (например, визуально ближайших или, наоборот, удаленных) с известной 
    классификацией», Чем отличается данный объект от другого объекта или группы 
    объектов с известной классификацией» и т.п. Ответы даются в виде пересечения 
    описания неизвестного объекта с описаниями объектов, которые оптимизированы 
    привязкой контекстно-зависимых локальных метрик. Совокупность таких ответов, 
    индивидуальных для каждого нового случая, обладает полиморфностью, свойственной 
    естественному языку при описании явлений со сложной системной организацией, 
    и обеспечивает объяснение принятых решений посредством аргументации. Здесь 
    нет дерева логического вывода. Ответы воспринимаются параллельно. Они как 
    бы бросаются на чашу весов, и их множество может расширяться до довольно больших 
    величин (в зависимости от количества привлекаемых для аргументации объектов 
    и сочетаний объектов). <br>
    Для иллюстрации некоторых из вышеперечисленных возможностей применения контекстно-зависимых 
    локальных метрик и геометрического подхода рассмотрим следующий пример. <br>
    На рис. 1 представлены изображения лиц 16 людей. Они разбиты на два класса. 
    Ставилась задача найти закономерности такого разбиения. <br>
    Прежде всего были выделены бинарные признаки, характеризующие изображенные 
    лица. Это следующие характеристики: <br>
    x_1 голова : круглая - 1, овальная - 0; <br>
    x_2 уши: оттопыренные - 1, прижатые - 0; <br>
    x_3 нос: круглый - 1, длинный - 0; <br>
    x_4 глаза: круглые - 1, узкие - 0; <br>
    x_5 лоб: с морщинами - 1, без морщин – 0; <br>
    x_6 складка: носогу6нал складка есть -1, носогубной складки нет – 0;<br>
    x_7 губы: толстые - 1, тонкие - 0; <br>
    x_8 волосы: есть - 1, нет - 0; <br>
    x_9 усы: есть - 1, нет - 0; <br>
    x_10 борода: есть - 1, нет - 0; <br>
    x_11 очки: есть - 1, нет - 0; <br>
    x_12 родинка: родинка на щеке есть - 1, родинки на щеке нет - о;<br>
    x_13 бабочка: есть - 1, нет - 0; <br>
    x_14 брови: подняты кверху .- 1, опущены вниз – 0;<br>
    x_15 серьга: есть - 1, нет - 0; <br>
    x_16 трубка: курительная трубка есть - 1, нет- 0. </p>
  <p align="justify">Исходная матрица данных, соответствующая изображенным лицам, 
    представлена в табл.1. Строки соответствуют объектам (N = 16), столбцы бинарным 
    признакам (р = 16). <br>
    Объекты с номерами 1-8 относятся к классу _1, а с номерами 9-16 - к классу 
    _2.</p>
  <p align="justify"> <img src="img/file_01_01.png" width="640" height="484"><br>
    Рисунок 1. Изображения лиц людей<br>
    Таблица 1. Исходная матрица данных<br>
    <img src="img/file_01_02.png" width="640" height="320"> </p>
  <p align="justify">На первом этапе производился анализ представленных данных 
    с помощью традиционных методов прикладной статистики, содержащихся в пакете 
    StatGraphics Plus for Windous. Как показывает проведенный анализ, в исходном 
    пространстве признаков объекты разных классов перемешаны друг с другом. Об 
    этом говорят результаты иерархического группирования (дендрограмма на рис.2) 
    и проекция объектов в пространство первых З-х главных компонент, на которые 
    приходится более 52% общей дисперсии. <br>
    <img src="img/file_01_03.png" width="388" height="270"><br>
    Рисунок 2. Результат иерархической кластеризации в исходном пространстве признаков</p>
  <p align="justify">Вместе с тем дискриминантный анализ привел к положительному 
    эффекту разделения классов (применялась версия дискриминантного анализа с 
    использованием процедур последовательного увеличения и уменьшения группы признаков). 
    Получена следующая дискриминантная функция: <br>
    g(x)=-1.7+7.3x_2+2.4x_4+7.4x_7-5.5x_8+1.6x_10+10.0x_12+4.9x_13<br>
    Как видно из рис. 3 (график «усатый ящик»), дискриминантная функция обеспечивает 
    полное разделение классов _1 и _2. Если стремиться только к формальному 
    эффекту, то на таком убедительном результате разделения классов можно остановиться. 
    Однако в данном случае достигнутому формальному эффекту в незначительной степени 
    сопутствует формирование новых знаний о структуре анализируемых данных. Единственное, 
    что можно сказать, - это перечислить признаки и веса, с которыми они вошли 
    в линейную дискриминатную функцию. «За кадром» остается внутреннее строение 
    классов и данных в целом, которое, как будет показано ниже, может быть достаточно 
    интересным и раскрытие которого может дать качественно новую информацию. Указанное 
    раскрытие с использованием контекстно-зависимых локальных метрик и изложенного 
    геометрического подхода являлось целью второго этапа анализа данных. <br>
    В качестве критерия качества локальных метрик применялась следующая величина: 
    <br>
    J=N_i (4)=max,<br>
    Где N_i (4)- количество объектов из класса, которому принадлежит x_i, вошедших 
    в группу 4-х ближайших к x_i объектов. <br>
    Локальные метрики вида d_ij^((L))=w_i^T |x_i-x_j |,(_ik=01) для каждого 
    объекта x_i находились с помощью алгоритма случайного поиска с адаптацией 
    (СПА) (Лбов Г. с., 1965). Проводилась серия опытов по случайному определению 
    состава группы n признаков из множества исходных 16 признаков. Для каждой 
    группы вычислялось значение критерия. Группа с минимальным значением критерия 
    поощрялась увеличением вероятности выбора ее признаков в следующих сериях 
    опытов, а группа с наибольшей величиной наказывалась соответствующим образом. 
    Эта процедура повторялась до тех пор, пока не выделилась группа признаков 
    с явно преобладающей над другими вероятностью ее выбора. Количество опытов 
    в серии, объем группы признаков, а также меры поощрения и наказания признаков 
    подбирались эмпирически. </p>
  <p align="justify"><img src="img/file_01_04.png" width="424" height="274"> </p>
  <p align="justify">Рисунок 3. Результаты дискриминантного анализа</p>
  <p align="justify">Таблица 2. Результат применения СПА<br>
    <img src="img/file_01_05.png" width="628" height="366"> </p>
  <p align="justify">Результат работы алгоритма СПА показан в табл. 2, где отобранные 
    признаки обведены рамкой. Например, для l-го объекта в локальную метрику <br>
    вошли признаки x_1,x_6,x_11 и x_16; для 2-го - x_4,x_5,x_10,x_15 и т. д. Отметим. 
    что применение на этих же данных алгоритма последовательного уменьшения группы 
    признаков дало несущественно отличающиеся результаты. <br>
    Таблица 3. Матрица расстояний в исходном пространстве признаков <br>
    <img src="img/file_01_06.png" width="628" height="338"><br>
    Следующим шагом анализа 6ыло вычисление d^((s))-расстояний между объектами 
    с оптимизированными описаниями и группирование объектов и признаков. В та6л. 
    3 приведена матрица расстояний между объектами в исходном пространстве признаков, 
    а в табл. 4 дана матрица расстояний между объектами, измеренных в локальных 
    метриках D^((L)).<br>
    Для нахождения d^((s))- расстояний в данном случае применялось прямое вычисление 
    расстояний Хэмминга между строками матрицы D^((L)). Результаты вычисления, 
    на основании которого было проведено группирование объектов, показаны в табл.5. 
    Эти же результаты, дополненные группированием признаков, которое выразилось 
    в их перестановке местами, отображены в та6л. 6.</p>
  <p align="justify"> Таблица 4. Расстояния в локальных метриках<br>
    <img src="img/file_01_07.png" width="628" height="318"> </p>
  <p align="justify">Как следует из приведенных та6лиц, определение локальных 
    метрик привело, как и при применении дискриминантного анализа, к полному разделению 
    классов _1и _2.<br>
    Но при этом стало ясно, какую роль играют признаки и сочетания их значений 
    в проявившейся структуре множества объектов. Видно, что для достижения полученного 
    эффекта разделения классов важными оказались все признаки. В то же время в 
    каждом классе выделилось по две самостоятельные группировки объектов, для 
    каждой из которых характерно строго определенное сочетание значений со6ственных 
    признаков. <br>
    Таблица 5. Матрица -расстояний<br>
    <img src="img/file_01_08.png" width="472" height="252"> </p>
  <p align="justify">Таблица 6. Перегруппированные данные<br>
    <img src="img/file_01_09.png" width="628" height="286"><br>
    В целом, визуально d^((s))- структура множества объектов с привязанными к 
    ним локальными метриками представляется в виде четырехгранника (рис. 4). <br>
    Исходя из полученной структуры, композицию, достаточную для представления 
    классов _1 и _2 составят 4 объекта (4 конъюнкции элементарных со6ытий), по 
    одному из выделенных группировок. Соответственно правило вывода для принятия 
    решения о принадлежности объектов какому-либо классу имеет следующий вид: 
    <br>
    [(x_1=0)(x_6=1)(x_11=1)(x_16=1)][(x_4=1)(x_5=0)(x_10=1)(x_15=0)]_1<br>
    [(x_3=1)(x_8=0)(x_9=1)(x_14=1)][(x_2=1)(x_7=1)(x_12=0)(x_13=1)]_2</p>
  <p align="justify"> <img src="img/file_01_10.png" width="448" height="292"><br>
    Рисунок 4. Геометрическая структура логических закономерностей</p>
</div>
<div align="justify">На практике, конечно, встречаются гораздо более сложные ситуации, 
  чем в приведенном примере. В следующем разделе будет рассмотрен вариант применения 
  геометрического подхода для базы знаний реальной экспертной системы медицинской 
  диагностики. Выбор же приведенного примера обусловлен желанием просто и выразительно 
  продемонстрировать некоторые возможности применения контекстно-зависимых локальных 
  метрик и геометрического подхода при решении задач формирования знаний. Он показывает, 
  что по-строение для каждого эмпирического факта собственной локальной метрики, 
  оптимизирующей в заданном контексте иерархию его геометрической близости к другим 
  фактам, позволяет существенно уменьшить число элементарных событий, подлежащих 
  дальнейшему анализу. И, кроме того, геометрическое изображение структуры множества 
  объектов с оптимизированными описаниями посредством d^((s))-метрик дает наглядное 
  визуальное представление об ее особенностях, что помогает формированию результирующего 
  правила вывода. <br>
  Интересными представляются возможности применения описанного подхода для анализа 
  совокупности объектов при отсутствии информации об их группировании в какие-либо 
  классы. В этом случае в целях конструирования локальных метрик искусственно 
  создается альтернативный класс из равномерно распределенных объектов. Тогда 
  сконструированные локальные метрики оптимизируют описание каждого объекта таким 
  образом, что в нем остается только то, что является важным для выражения отличия 
  структуры анализируемой совокупности от случайно организованной структуры данных. 
  Эта задача нуждается в особом рассмотрении.<br>
  Описанный подход к формированию знаний может быть реализован в разнообразных 
  вариантах. Такое разнообразие обусловлено различными употребляемыми критериями 
  качества локальных метрик, алгоритмами определения их параметров и видами<br>
  d^((s))- метрик. Здесь исследователю предоставляется широкое поле для экспериментирования 
  и выбора наилучшего варианта при решении конкретной задачи формирования знаний. 
  <br>
  Конкретные практические приложения геометрического подхода представляются наиболее 
  эффективными для поиска закономерностей структуры данных и построения баз знаний 
  в следующих областях: <br>
  - Прикладная химия (прогнозирование свойств химических соединений). <br>
  - Медицинская диагностика. <br>
  - Психологическая диагностика. <br>
  - Исследование взаимосвязей различных уровней биоорганизации. <br>
  - Социально-психологические исследования. <br>
  - Генетика и др.<br>
</div>
  <div align="justify"></div>
<blockquote>
  <table border="0" cellpadding="0" cellspacing="0">
    <tr> 
      <td><a href="main12.htm" target="_self" onClick="MM_nbGroup('down','group1','Menu','',1)" onMouseOver="MM_nbGroup('over','Menu','','',1)" onMouseOut="MM_nbGroup('out')"><img src="img/Menu.gif" alt="" name="Menu" width="73" height="22" border="0" onload=""></a></td>
      <td><a href="002.htm" target="_self" onClick="MM_nbGroup('down','group1','For','',1)" onMouseOver="MM_nbGroup('over','For','','',1)" onMouseOut="MM_nbGroup('out')"><img src="img/For.gif" alt="" name="For" width="73" height="22" border="0" onload=""></a></td>
    </tr>
  </table>
</blockquote>
<div align="center"></div>
</body>
</html>
